---
layout: archive
title: ""
permalink: /portfolio/
author_profile: true
---

<h1 style="font-size:1.8em; margin-bottom:25px;">Portfolio</h1>

<h2 style="font-size:1.8em; margin-bottom:25px;">Research-based Projects</h2>

<!-- Soft Robotic Snake -->
<div style="display:flex; align-items:center; justify-content:space-between; margin-bottom:40px; flex-wrap:wrap;">
  <div style="flex:1; min-width:250px; margin-right:20px;">
    <h2 style="margin:0; font-size:1.3em;">Soft Robotic Snake Robot</h2>
    <em>University of Massachusetts Amherst · 2024 – Present</em>
      <p style="margin-top:10px;">
     Snakes are capable of traversing various substrates by employing distinct locomotion gaits, including lateral undulation, 
     concertina, and sidewinding. Implementing this versatility to robotic systems has the potential for various applications, 
     including search and rescue operations, environmental surveying, and other field tasks. Earlier studies proposed that snakes rely
     on push points to generate forward propulsion (Gray, 1946); however, recent studies indicate that anisotropic friction created by ventral snake scales
     plays a more significant role in snake locomotion (Hu, 2009), which generate more friction in backward direction than in the forward direction. 
        Therefore, the motivation of this study is to develop a snake-inspired soft robot capable of utilizing friction to generate locomotion. The design of the  vertebrae, 
    ribs and scales were inspired by biological snakes. McKibben pneumatic muscle actuators are also used to mimic snake muscles; iliocostalis and the semispinalis.
<hr>
    These project involves:
<ul>
  <li>Designing snake-inspired components in SolidWorks and fabricating prototypes using 3D printing.</li>
  <li>Elastomer molding to create and evaluate bioinspired scale structures for frictional anisotropy.</li>
  <li>Designing and executing locomotion & friction experiments to assess performance on various surface conditions.</li>
  <li>Performing material testing to analyze bonding performance between elastomers and thermoplastics.</li>

</ul>     
    <p style="margin-top:10px; font-style:italic;">
  Findings below are presented in: Y. Nandwana, <strong>U. Sen</strong>, G. Olson, “A Highly Articulated Backbone for Soft Snake Robots,” <em>Living Machines</em>, Sheffield, UK, 2025. [Accepted]
</p>

     </p>
  </div>
  
</div>

<!-- Vertical image gallery for Soft Robotic Snake -->
<div style="display:flex; flex-direction:column; align-items:center; gap:25px; margin-bottom:40px;">
  <div style="text-align:center;">
    <img src="{{ '/images/snake1.png' | relative_url }}" alt="Snake Prototype Fabrication" style="width:600px; border-radius:10px;">
    <p style="margin-top:5px; font-size:0.95em;">The robot and snake-inspired vertebrate design</p>
  </div>
  <div style="text-align:center;">
    <img src="{{ '/images/snake2.png' | relative_url }}" alt="Friction Testing" style="width:600px; border-radius:10px;">
    <p style="margin-top:5px; font-size:0.95em;">Scale details and their attachment to the robot</p>
  </div>
  <div style="text-align:center;">
    <img src="{{ '/images/snake5.png' | relative_url }}" alt="Locomotion Experiment" style="width:600px; border-radius:10px;">
    <p style="margin-top:5px; font-size:0.95em;">Bending capabilities of the robot</p>
  </div>
  <div style="text-align:center;">
    <img src="{{ '/images/snake4.png' | relative_url }}" alt="3D-Printed Components" style="width:600px; border-radius:10px;">
    <p style="margin-top:5px; font-size:0.95em;">Locomotion performance of the robot.</p>
  </div>
</div>

  <div style="margin-top:25px; text-align:center;">
    <p style="margin-bottom:8px;"><strong>Locomotion Video</strong></p>
    <video width="700" controls>
      <source src="{{ '/images/snake_compressedVideo.mp4' | relative_url }}" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>

<hr>

<!-- Wrist-Worn Haptic Device -->
<div style="display:flex; align-items:center; justify-content:space-between; margin-bottom:40px; flex-wrap:wrap;">
  <div style="flex:1; min-width:250px; margin-right:20px;">
    <h2 style="margin:0; font-size:1.3em;">Wrist-Worn Haptic Device</h2>
    
    This project involved the design and implementation of a wrist-worn haptic interface capable of delivering tactile feedback through a custom voice-coil actuator. 
    The goal was to transfer haptic feedback from the fingertip to the wrist, enabling more free fingertip movement for interactions in virtual and augmented reality (VR & AR) environments.
    The system was developed as part of a senior thesis and integrates mechanical, electronic, and software subsystems. 
    The custom voice-coil actuator consists of a magnet and a wire coil wound around a cylindrical core. Its feedback intensity and frequency can be tuned by adjusting design parameters such as coil height, wire thickness, coil diameter, and magnet strength.
    Through extensive prototyping and user evaluation, the device demonstrated reliable actuation performance and was validated through user studies on stiffness discrimination, leading to two publications at IEEE World Haptics 2023.

<ul style="margin-top:10px;"> <li>Developed a custom voice-coil actuator using neodymium magnets and optimized coil geometry for enhanced force output.</li> 
  <li>Designed and fabricated a wrist-worn mechanical case through iterative 3D printing (10+ prototypes) ensuring consistent haptic feedback and ergonomics.</li> 
  <li>Implemented embedded control firmware enabling real-time actuation and sensor feedback via Unity3D-based control interface</li> 
  <li>Conducted user studies confirming the system’s ability to convey tactile cues with adjustable force profiles.</li> </ul>
  <li>Implemented actuation parameters such as duty cycle and frequency to control the intensity of the feedback for different interactions.</li> </ul>

  </div>
</div>

<!-- Vertical image gallery for Haptic Device -->
<div style="display:flex; flex-direction:column; align-items:center; gap:25px; margin-bottom:40px;">
  <div style="text-align:center;">
    <img src="{{ '/images/ww1.png' | relative_url }}" alt="Device Design" style="width:500px; border-radius:10px;">
    <p style="margin-top:5px; font-size:0.95em;">
     Demonstrates the actuator’s operation and force response under varying duty cycles.
     (From: DOI: 10.1109/LRA.2024.3360815)</p>
  </div>
  <div style="text-align:center;">
    <img src="{{ '/images/ww2.png' | relative_url }}" alt="Electronics Assembly" style="width:500px; border-radius:10px;">
    <p style="margin-top:5px; font-size:0.95em;">Shows user discrimination accuracy across actuator duty cycles. (From: DOI: 10.1109/LRA.2024.3360815)
</p>
  </div>
  <div style="text-align:center;">
    <img src="{{ '/images/ww3.png' | relative_url }}" alt="Testing Setup" style="width:500px; border-radius:10px;">
    <p style="margin-top:5px; font-size:0.95em;">Soft satin fabric ensures comfortable and stable contact while maintaining consistent force transmission.</p>
  </div>
  <div style="text-align:center;">
    
    <!-- Two images side by side -->
<div style="display:flex; justify-content:center; align-items:flex-start; gap:20px; margin-bottom:10px;">
  <img src="{{ '/images/ww4.png' | relative_url }}" alt="Control Board" style="width:500px; border-radius:10px;">
  <img src="{{ '/images/ww5.png' | relative_url }}" alt="Additional Board View" style="width:500px; border-radius:10px;">
</div>
    <p style="margin-top:5px; font-size:0.95em;">Compact two-layer board that integrates control, sensing, and actuation electronics.</p>
  </div>
</div>




<!-- Haptic Game Development -->
<div style="display:flex; align-items:center; justify-content:space-between; margin-bottom:40px; flex-wrap:wrap;">
  <div style="flex:1; min-width:250px; margin-right:20px;">
    <h2 style="margin:0; font-size:1.3em;">Haptic Game Development</h2>
    <em>Kadir Has University · 2024</em>

    <p style="margin-top:10px;">
      This project introduced a smartphone-based game developed in 
      Unity3D to investigate how varying forms of 
      haptic feedback affect user performance and engagement. 
      The objective was to build a gamified psychophysical testing platform, offering 
      a more engaging alternative to traditional tactile perception experiments. 
      By integrating vibration-based feedback through smartphone actuators, the game allows systematic 
      exploration of tactile response within an enjoyable mobile gaming environment. 
    </p>

    <ul style="margin-top:10px;">
      <li>Developed in Unity for iOS platforms with optimized haptic rendering.</li>
      <li>Designed an endless runner gameplay system, where the player navigate paths and avoid obstacles using on-screen arrow controls.</li>
      <li>Implemented three haptic feedback modes with Interhaptics Composer, ranging from collision-based cues to predictive haptic guidance before wall contact.</li>
      <li>Employed procedural path generation with dynamically varying wall angles to ensure continuous, unpredictable gameplay for testing user adaptability and response time performance.</li>
      <li>Enabled real-time data collection of user actions — collisions, inputs, and transitions between haptic regions — for psychophysical analysis.</li>
      <li>Aimed to create a fun, accessible, and research-driven tool for studying multisensory interaction and human response under mobile gaming conditions.</li>
    </ul>
  </div>
</div>

<!-- Image placeholders -->
<div style="width:100%; text-align:center; margin-top:20px;">

  <div style="margin-bottom:20px;">
    <img src="{{ '/images/haptic_walls.png' | relative_url }}" 
         alt="Haptic Game Interface" 
         style="width:500px; max-width:100%; border-radius:10px;">
   <p style="font-size:0.9em; color:#555;">
  Screenshots of the mobile game during a playthrough. The player (a white ball) appears at the bottom of the screen, navigating a path bordered by brown walls. 
  Movement along the x-axis is controlled via on-screen arrow buttons, while progression along the y-axis occurs automatically. 
  The images show: (a) the start of the game, (b) a collision with the left wall, and (c) recovery back to the center path.
</p>

  </div>

  <div style="margin-bottom:20px;">
    <img src="{{ '/images/FeedbackLevel.png' | relative_url }}" 
         alt="Unity Game Environment" 
         style="width:500px; max-width:100%; border-radius:10px;">
<p style="font-size:0.9em; color:#555;">
  Representation of three haptic feedback modes: (i) fixed feedback triggered only on collision, 
  (ii) variable feedback intensity based on the ball’s penetration depth into the wall, and 
  (iii) predictive haptic guidance that increases in strength as the ball approaches and contacts the wall.
</p>  </div>

</div>



<h2 style="font-size:1.8em; margin-bottom:25px;">Course & Competition Projects</h2>

<!-- Pod Design for Hyperloop Competition -->
<div style="display:flex; align-items:center; justify-content:space-between; margin-bottom:40px; flex-wrap:wrap;">
  <div style="flex:1; min-width:250px; margin-right:20px;">
    <h2 style="margin:0; font-size:1.3em;">Pod Design for Hyperloop Competition</h2>
    <em>National Hyperloop Competition · 2022</em>

    <p style="margin-top:10px;">
      This project was developed for a <strong>national (Türkiye) Hyperloop competition</strong>, where our team received the 
      <strong>Best Technical Design Report Award</strong>. I worked as part of the 
      <strong>Navigation and Electronics Team</strong>, and focused on the design and testing of the systems that guided and monitored 
      the pod’s movement inside the tunnel. My main goal was to build a reliable and accurate navigation setup that could 
      work at high speeds using multiple sensors and Arduino-based control systems.
    </p>

    <ul style="margin-top:10px;">
      <li>Designed a reflector-based navigation system using laser sensors and Arduino Due to detect tunnel reflectors at speeds up to 26 m/s.</li>
      <li>Wrote and tested Arduino scripts to calculate velocity and displacement from reflector detection intervals.</li>
      <li>Contributed to design of a redundant sensor layout with five laser modules to reduce error through majority voting logic.</li>
      <li>Developed a backup tachometer system using TCRT5000 IR sensors to track wheel rotation when laser sensors failed.</li>
      <li>Integrated MPU6050 IMU and height IR sensors to measure acceleration, tilt, and levitation height of the pod.</li>
      <li>Matched sampling frequencies and designed an optimized signal flow between sensors and the main computer to ensure realiable data transmission.</li>    </ul>
  </div>
</div>

<!-- Image placeholders -->
<div style="width:100%; text-align:center; margin-top:20px;">

  <div style="margin-bottom:20px;">
    <img src="{{ '/images/lasersensors.png' | relative_url }}" 
         alt="Pod Navigation Setup" 
         style="width:500px; max-width:100%; border-radius:10px;">
<p style="font-size:0.9em; color:#555;">Placement of laser sensors used for pod navigation and reflector detection.</p>
  </div>

  <div style="margin-bottom:20px;">
    <img src="{{ '/images/navigation system.png' | relative_url }}" 
         alt="Sensor Integration" 
         style="width:500px; max-width:100%; border-radius:10px;">
<p style="font-size:0.9em; color:#555;">
  Overall system architecture illustrating the integration of sensors with the microcontroller and master computer for pod navigation.
</p>

  </div>

<div style="display:flex; justify-content:center; align-items:flex-start; gap:20px; margin-bottom:10px;">
  <img src="{{ '/images/realPod1.jpg' | relative_url }}" alt="Control Board" style="width:500px; border-radius:10px;">
  <img src="{{ '/images/realPod2.jpg' | relative_url }}" alt="Additional Board View" style="width:500px; border-radius:10px;">
</div>
 <p style="font-size:0.9em; color:#555;">
  Manufactured pod placed on the competition track.
</p>
</div>
</div>


<!-- Robotic Teleoperation System -->
<div style="margin-bottom:50px;">

  <h2 style="margin:0; font-size:1.3em;">Robotic Teleoperation System</h2>
  <em>Class Project · Low-cost dual-arm teleoperation platform using ROS and Arduino · 2023</em>
  <!-- Summary paragraph -->
  <p style="margin-top:10px;">
    This class project presents a low-cost robotic teleoperation system composed of a controller arm
    and a teleoperated arm, both designed and 3D-printed. Joint angles are measured using
    potentiometers and transmitted via ROS to replicate the controller arm’s motion on the teleoperated
    arm. The system demonstrates real-time position mapping and reliable pick-and-place tasks, with a
    measured communication delay of <strong>0.3–0.5 seconds</strong> observed through video analysis.
  </p>

  <!-- Bullet points -->
  <ul style="margin-top:10px;">
    <li>Designed and fabricated two kinematically similar robotic arms using SG90 servos and 3D-printed PLA components.</li>
    <li>Used potentiometers as joint sensors, minimizing cost while maintaining accurate position feedback</li>
    <li>Implemented a ROS-based publisher–subscriber system for wireless bidirectional teleoperation.</li>
    <li>Validated real-time control through pick-and-place tasks (very light objects due to SG90 servo performance) with delay measurements derived from frame-by-frame video analysis.</li>
  </ul>

<!-- Image grid: 2 rows, 2 images per row with explanations -->
<div style="display:flex; flex-direction:column; align-items:center; gap:20px; margin-top:20px;">

  <!-- Row 1 -->
 <!-- Row with two images side by side -->
<div style="display:flex; justify-content:center; align-items:flex-start; gap:20px; margin-bottom:10px;">
  <img src="{{ '/images/controller1.png' | relative_url }}" alt="Control Board" style="width:500px; border-radius:10px;">
  <img src="{{ '/images/controller2.png' | relative_url }}" alt="Additional Board View" style="width:500px; border-radius:10px;">
</div>
  <p style="text-align:center; font-size:0.95em; max-width:1000px; margin-top:8px;">
    <strong>Controller Arm:</strong> 3D-printed design and assembly of the master arm used to control the teleoperated manipulator. 
    Potentiometers are integrated into each joint for angular position sensing and transmission via ROS interface
  </p>

  <!-- Row 2 -->
  <!-- Row with two images side by side -->
<div style="display:flex; justify-content:center; align-items:flex-start; gap:20px; margin-bottom:10px;">
  <img src="{{ '/images/teleoperated1.png' | relative_url }}" alt="Control Board" style="width:500px; border-radius:10px;">
  <img src="{{ '/images/teleoperated2.png' | relative_url }}" alt="Additional Board View" style="width:400px; border-radius:10px;">
</div>
  <p style="text-align:center; font-size:0.95em; max-width:1000px; margin-top:8px;">
    <strong>Teleoperated Arm:</strong> Replicated arm executing the controller’s movements in real time.
  </p>

</div>


 <!-- Single image below -->
<div style="text-align:center; margin-top:20px;">
  <img src="{{ '/images/architecture.png' | relative_url }}" 
       alt="System Overview" 
       style="width:500px; max-width:100%; border-radius:10px;">
  <p style="text-align:center; font-size:0.95em; max-width:1000px; margin-top:8px;">
    <strong>System Architecture:</strong> Overview of the teleoperation framework showing the data flow between the 
    controller and teleoperated arms through the ROS publisher–subscriber system. Each joint angle is obtained 
    via potentiometers and transmitted to replicate movement on the teleoperated side. The setup enables low-cost, 
    real-time wireless control.
  </p>
</div>


  <!-- Embedded video (local .mp4) -->
  <div style="margin-top:25px; text-align:center;">
    <p style="margin-bottom:8px;"><strong>Demonstration Video</strong></p>
    <video width="700" controls>
      <source src="{{ '/images/Demo4.mp4' | relative_url }}" type="video/mp4">
      Your browser does not support the video tag.
    </video>
  </div>

</div>




<hr>

<hr>
<hr>

